{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f031f658",
   "metadata": {},
   "source": [
    "\n",
    "# Karuna Vikram kv2320\n",
    "# 12/13/21\n",
    "# file: Computational Linguistics Project 3\n",
    "# This file contains Project 3, analysis of the Govt of India's official memos on vaccines and immunity during the Covid-19 pandemic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ce6ddb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/karuna/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "import requests\n",
    "import string\n",
    "import random\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "from readability import Readability\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from nltk.corpus import nps_chat\n",
    "from nltk.sentiment import SentimentAnalyzer as sentAn\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer as sentAn\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "import matplotlib.pyplot as pl\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "#!pip install wordcloud\n",
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37c58269",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening and reading text file\n",
    "with open('1002Project3IndiaCovid.txt') as f:\n",
    "    IndiaVaxRaw = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fe84444",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning the text\n",
    "#no other paratext or table of contents\n",
    "IndiaVaxRaw = IndiaVaxRaw.replace('', '')\n",
    "IndiaVaxRaw = IndiaVaxRaw.replace('●', '')\n",
    "IndiaVaxRaw = IndiaVaxRaw.replace('▪', '')\n",
    "IndiaVaxRaw = IndiaVaxRaw.replace('*****', '')\n",
    "IndiaVaxRaw = IndiaVaxRaw.replace('●', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e781a7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TEXT 1 PREGNANT WOMEN\\n1 FAQs on COVID-19 Vaccines and Vaccination Program A. GENERAL 1. Which COVID-19 vaccines are licenced and used in the country at present for COVID Vaccination? Three vaccines th'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IndiaVaxRaw[:200] #checking to see the text was opened correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99b6c228",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividing the text into 5 sections\n",
    "start = IndiaVaxRaw.index('TEXT 1 PREGNANT WOMEN') #each text was marked at its start in the original file\n",
    "end = IndiaVaxRaw.index('TEXT 2 REVISED NATIONAL GUIDELINES') #using those markings to split the text \n",
    "pregnantWomen = IndiaVaxRaw[start: end]\n",
    "\n",
    "start = IndiaVaxRaw.index('TEXT 2 REVISED NATIONAL GUIDELINES') \n",
    "end = IndiaVaxRaw.index('TEXT 3 ELDERLY AND DIFFERENTLY ABLED') \n",
    "nationalGuidelines = IndiaVaxRaw[start: end]\n",
    "\n",
    "start = IndiaVaxRaw.index('TEXT 3 ELDERLY AND DIFFERENTLY ABLED') \n",
    "end = IndiaVaxRaw.index('TEXT 4 WITHOUT ID') \n",
    "elderly = IndiaVaxRaw[start: end]\n",
    "\n",
    "start = IndiaVaxRaw.index('TEXT 4 WITHOUT ID') \n",
    "end = IndiaVaxRaw.index('TEXT 5 IMMUNITY AYUSH') \n",
    "ID = IndiaVaxRaw[start: end]\n",
    "\n",
    "start = IndiaVaxRaw.index('TEXT 1 PREGNANT WOMEN') \n",
    "end = IndiaVaxRaw.index('TEXT 5 IMMUNITY AYUSH') \n",
    "ayush = IndiaVaxRaw[start: end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6582128c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the corpus of India memos on Covid vaccination by loading the individual memos into a dictionary\n",
    "IndiaVax = {}\n",
    "IndiaVax['pregnantWomen']= pregnantWomen \n",
    "IndiaVax['nationalGuidelines']= nationalGuidelines\n",
    "IndiaVax['elderly']= elderly\n",
    "IndiaVax['ID']= ID\n",
    "IndiaVax['ayush']= ayush"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c9a2770",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function randomly slices 200 characters of inputted text\n",
    "def randomSlicing(text):\n",
    "    a = len(text) - 201 #to make sure the starting point is at least 200 characters from the end\n",
    "    b = int(random.randrange(0, a)) #random int between 0 and a    \n",
    "    c = b + 200 #200 charecters from a\n",
    "    text = text[b:c] #slice\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ef05300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "veillance, regional cooperation and assisting neighbouring countries, communication & media response etc. 2. What are the principles followed for selecting the priority groups for vaccination? The pri\n"
     ]
    }
   ],
   "source": [
    "randomSlicing(pregnantWomen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d52aef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le and scalable, headed by CEO, National Health Authority. India's COVID vaccination program incorporates recommendations of the foremost experts in the field of immunization, public health, disease c\n"
     ]
    }
   ],
   "source": [
    "randomSlicing(nationalGuidelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbee7125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and reporting in Co-WIN including AEFIs reporting and management (refer to operational guidelines) https://www.mohfw.gov.in/pdf/COVID19VaccineOG111Chapter16.pdf 6. Line listing of Beneficiaries o For \n"
     ]
    }
   ],
   "source": [
    "randomSlicing(elderly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abfe5759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d other logistics o Block / Urban Task Force will ensure sufficient awareness and visibility for vaccination. 9. Organizing a Near to Home Covid Vaccination Centre (NHCVC) o A five-member team 'Vaccin\n"
     ]
    }
   ],
   "source": [
    "randomSlicing(ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b977c4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f the dose schedule, the 2nd dose should be deferred by 3 months from clinical recovery from COVID-19 illness. iv. Persons with any serious general illness requiring hospitalization or ICU case should\n"
     ]
    }
   ],
   "source": [
    "randomSlicing(ayush)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21acf59c",
   "metadata": {},
   "source": [
    "### Write a paragraph or two about your corpus. Why did you choose it? How did you organize it? What genres does it belong to? What, if anything, is distinctive about its language? And what do you expect to find in your computational analysis?\n",
    "\n",
    "This corpus is collection of memos from the Ministry of Health and Family Welfare in the Government of India. They were accessed here:https://www.mohfw.gov.in/ The government has released many memos over the course of the COVID-19 pandemic dealing from how to social distance to how to dispose of dead bodies of infected persons from the home. This corpus though contains documents specifically about vaccines, vaccine hesitancy, vaccine access, and immunity. The five texts that are included pretty span the 10 months that vaccines have been rolled out in India. From oldest to newest they are ayush, ID, elderly, nationalGuidelines, and pregnantWomen. I tried to to address five separate issues pertinent to vaccination in my choice of texts. Ayush deals with immunity, specifically home remedies and Ayurveda and immunity. The government seems to be promoting certain home remedies as able to help safeguard somewhat against Covid. ID is about government policies outlining how migrant populations without IDs can still access vaccines. Elderly is about special plans for vaccination drives to be accessible to the elderly and differently abled populations. NationalGuidelines is the most broad, encapsulating the broad guidelines of the govt of India with respect to its vaccine policy. Finally, pregnantWomen outlines the health risks pregnantWomen might face if they take the vaccine.\n",
    "\n",
    "These are government documents, so the language is straightfoward but inelegant. There are no idioms or other illustrative or flowery language. The text plainly means what it says.\n",
    "\n",
    "In my analysis, I hope to discover state attitudes towards vaccination. Is it trying to persuade people to take the vaccine? How can the rhetoric of public health reflect state control and power? Are certain groups being marginalized? After all, government organized vaccination is a political project--one which brings to the surface crucial and fraught questions of state power, civic duty, and individual autonomy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75a87b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizing the text\n",
    "#the tokenizer is able to deal with words that have contractions, like \"don't\"\n",
    "#tokenizer removes punctuation\n",
    "pregnantWomenToken = nltk.tokenize.regexp_tokenize(pregnantWomen, \"[\\w']+\")\n",
    "nationalGuidelinesToken = nltk.tokenize.regexp_tokenize(nationalGuidelines, \"[\\w']+\")\n",
    "elderlyToken = nltk.tokenize.regexp_tokenize(elderly, \"[\\w']+\")\n",
    "IDToken = nltk.tokenize.regexp_tokenize(ID, \"[\\w']+\")\n",
    "ayushToken = nltk.tokenize.regexp_tokenize(ayush, \"[\\w']+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34715fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TEXT',\n",
       " '1',\n",
       " 'PREGNANT',\n",
       " 'WOMEN',\n",
       " '1',\n",
       " 'FAQs',\n",
       " 'on',\n",
       " 'COVID',\n",
       " '19',\n",
       " 'Vaccines',\n",
       " 'and',\n",
       " 'Vaccination',\n",
       " 'Program',\n",
       " 'A',\n",
       " 'GENERAL',\n",
       " '1',\n",
       " 'Which',\n",
       " 'COVID',\n",
       " '19',\n",
       " 'vaccines',\n",
       " 'are',\n",
       " 'licenced',\n",
       " 'and',\n",
       " 'used',\n",
       " 'in',\n",
       " 'the',\n",
       " 'country',\n",
       " 'at',\n",
       " 'present',\n",
       " 'for',\n",
       " 'COVID',\n",
       " 'Vaccination',\n",
       " 'Three',\n",
       " 'vaccines',\n",
       " 'that',\n",
       " 'have',\n",
       " 'been',\n",
       " 'granted',\n",
       " 'authorization',\n",
       " 'for',\n",
       " 'restricted',\n",
       " 'use',\n",
       " 'in',\n",
       " 'emergency',\n",
       " 'situation',\n",
       " 'by',\n",
       " 'the',\n",
       " 'Central',\n",
       " 'Drugs',\n",
       " 'Standard',\n",
       " 'Control',\n",
       " 'Organization',\n",
       " 'CDSCO',\n",
       " 'in',\n",
       " 'India',\n",
       " 'are',\n",
       " 'Covishield',\n",
       " 'r',\n",
       " \"AstraZeneca's\",\n",
       " 'vaccine',\n",
       " 'manufactured',\n",
       " 'by',\n",
       " 'Serum',\n",
       " 'Institute',\n",
       " 'of',\n",
       " 'India',\n",
       " 'Covaxin',\n",
       " 'r',\n",
       " 'manufactured',\n",
       " 'by',\n",
       " 'Bharat',\n",
       " 'Biotech',\n",
       " 'Limited',\n",
       " 'and',\n",
       " 'Sputnik',\n",
       " 'V',\n",
       " 'developed',\n",
       " 'by',\n",
       " 'Gamaleya',\n",
       " 'Research',\n",
       " 'Institute',\n",
       " 'Russia',\n",
       " 'which',\n",
       " 'is',\n",
       " 'the',\n",
       " 'third',\n",
       " 'vaccine',\n",
       " 'to',\n",
       " 'get',\n",
       " 'approval',\n",
       " 'from',\n",
       " 'the',\n",
       " 'Drugs',\n",
       " 'Controller',\n",
       " 'General',\n",
       " 'of',\n",
       " 'India',\n",
       " 'DCGI',\n",
       " '2',\n",
       " 'What',\n",
       " 'is',\n",
       " 'Emergency',\n",
       " 'Use',\n",
       " 'Authorization',\n",
       " 'EUA',\n",
       " 'Permission',\n",
       " 'for',\n",
       " 'restricted',\n",
       " 'use',\n",
       " 'Emergency',\n",
       " 'Use',\n",
       " 'Authorization',\n",
       " 'EUA',\n",
       " 'is',\n",
       " 'a',\n",
       " 'regulatory',\n",
       " 'mechanism',\n",
       " 'to',\n",
       " 'allow',\n",
       " 'the',\n",
       " 'use',\n",
       " 'of',\n",
       " 'vaccines',\n",
       " 'and',\n",
       " 'medicines',\n",
       " 'to',\n",
       " 'prevent',\n",
       " 'and',\n",
       " 'or',\n",
       " 'reduce',\n",
       " 'the',\n",
       " 'impact',\n",
       " 'of',\n",
       " 'life',\n",
       " 'threatening',\n",
       " 'diseases',\n",
       " 'or',\n",
       " 'conditions',\n",
       " 'as',\n",
       " 'caused',\n",
       " 'by',\n",
       " 'COVID',\n",
       " '19',\n",
       " 'However',\n",
       " 'before',\n",
       " 'grant',\n",
       " 'of',\n",
       " 'the',\n",
       " 'EUA',\n",
       " 'there',\n",
       " 'are',\n",
       " 'rigorous',\n",
       " 'assessments',\n",
       " 'of',\n",
       " 'laboratory',\n",
       " 'and',\n",
       " 'clinical',\n",
       " 'trial',\n",
       " 'data',\n",
       " 'including',\n",
       " 'data',\n",
       " 'on',\n",
       " 'quality',\n",
       " 'safety',\n",
       " 'production',\n",
       " 'of',\n",
       " 'protective',\n",
       " 'antibodies',\n",
       " 'and',\n",
       " 'efficacy',\n",
       " 'Safety',\n",
       " 'is',\n",
       " 'particularly',\n",
       " 'critical',\n",
       " 'aspect',\n",
       " 'of',\n",
       " 'this',\n",
       " 'scrutiny',\n",
       " 'and',\n",
       " 'a',\n",
       " 'risk',\n",
       " 'versus',\n",
       " 'benefit',\n",
       " 'evaluation',\n",
       " 'is',\n",
       " 'done',\n",
       " 'in',\n",
       " 'the',\n",
       " 'context',\n",
       " 'of',\n",
       " 'a',\n",
       " 'public',\n",
       " 'health',\n",
       " 'emergency',\n",
       " 'Full',\n",
       " 'licensure',\n",
       " 'is',\n",
       " 'obtained',\n",
       " 'when',\n",
       " 'the',\n",
       " 'manufacturer',\n",
       " 'submits',\n",
       " 'the',\n",
       " 'complete',\n",
       " 'data',\n",
       " 'EUA',\n",
       " 'by',\n",
       " 'Indian',\n",
       " 'regulators',\n",
       " 'is',\n",
       " 'aligned',\n",
       " 'with',\n",
       " 'global',\n",
       " 'guidelines',\n",
       " '3',\n",
       " 'Is',\n",
       " 'the',\n",
       " 'EUA',\n",
       " 'a',\n",
       " 'new',\n",
       " 'process',\n",
       " 'introduced',\n",
       " 'for',\n",
       " 'COVID',\n",
       " '19',\n",
       " 'Vaccine',\n",
       " 'Concept',\n",
       " 'of',\n",
       " 'EUA',\n",
       " 'always',\n",
       " 'existed',\n",
       " 'to',\n",
       " 'save',\n",
       " 'the',\n",
       " 'lives',\n",
       " 'of',\n",
       " 'people',\n",
       " 'all',\n",
       " 'over',\n",
       " 'the',\n",
       " 'world',\n",
       " 'with',\n",
       " 'vaccine',\n",
       " 'and',\n",
       " 'medicines',\n",
       " 'for',\n",
       " 'life',\n",
       " 'threatening',\n",
       " 'diseases',\n",
       " 'while',\n",
       " 'companies',\n",
       " 'continue',\n",
       " 'to',\n",
       " 'obtain',\n",
       " 'additional',\n",
       " 'safety',\n",
       " 'and',\n",
       " 'effectiveness',\n",
       " 'information',\n",
       " 'to',\n",
       " 'enable',\n",
       " 'full',\n",
       " 'licensure',\n",
       " 'Previously',\n",
       " 'EUAs',\n",
       " 'have',\n",
       " 'been',\n",
       " 'granted',\n",
       " 'to',\n",
       " 'vaccines',\n",
       " 'for',\n",
       " 'outbreaks',\n",
       " 'due',\n",
       " 'to',\n",
       " 'anthrax',\n",
       " 'Ebola',\n",
       " 'enterovirus',\n",
       " 'H7N9',\n",
       " 'influenza',\n",
       " 'and',\n",
       " 'Middle',\n",
       " 'East',\n",
       " 'respiratory',\n",
       " 'syndrome',\n",
       " 'As',\n",
       " 'of',\n",
       " 'January',\n",
       " '2021',\n",
       " 'nine',\n",
       " 'COVID',\n",
       " '19',\n",
       " 'vaccines',\n",
       " 'were',\n",
       " 'in',\n",
       " 'emergency',\n",
       " 'use',\n",
       " 'in',\n",
       " 'numerous',\n",
       " 'countries',\n",
       " 'around',\n",
       " 'the',\n",
       " 'globe',\n",
       " '4',\n",
       " 'Have',\n",
       " 'the',\n",
       " 'vaccines',\n",
       " 'undergone',\n",
       " 'the',\n",
       " 'needed',\n",
       " 'clinical',\n",
       " 'trials',\n",
       " 'before',\n",
       " 'EUA',\n",
       " 'Both',\n",
       " 'the',\n",
       " 'Indian',\n",
       " 'COVID',\n",
       " '19',\n",
       " 'vaccines',\n",
       " 'and',\n",
       " 'the',\n",
       " 'Russian',\n",
       " 'vaccine',\n",
       " 'Sputnik',\n",
       " 'V',\n",
       " 'have',\n",
       " 'conducted',\n",
       " 'their',\n",
       " 'phase',\n",
       " 'I',\n",
       " 'II',\n",
       " 'III',\n",
       " 'trials',\n",
       " 'Covishield',\n",
       " 'r',\n",
       " 'has',\n",
       " 'completed',\n",
       " 'its',\n",
       " 'Phase',\n",
       " 'III',\n",
       " 'trials',\n",
       " 'in',\n",
       " 'UK',\n",
       " 'and',\n",
       " 'the',\n",
       " 'bridging',\n",
       " 'trial',\n",
       " 'in',\n",
       " 'India',\n",
       " '2',\n",
       " '5',\n",
       " 'What',\n",
       " 'is',\n",
       " 'Phase',\n",
       " 'I',\n",
       " 'II',\n",
       " 'and',\n",
       " 'III',\n",
       " 'of',\n",
       " 'clinical',\n",
       " 'trial',\n",
       " 'for',\n",
       " 'a',\n",
       " 'vaccine',\n",
       " 'The',\n",
       " 'clinical',\n",
       " 'trial',\n",
       " 'phases',\n",
       " 'include',\n",
       " '6',\n",
       " 'Why',\n",
       " 'vaccination',\n",
       " 'is',\n",
       " 'not',\n",
       " 'provided',\n",
       " 'to',\n",
       " 'children',\n",
       " 'who',\n",
       " 'are',\n",
       " 'usual',\n",
       " 'target',\n",
       " 'COVID',\n",
       " '19',\n",
       " 'affects',\n",
       " 'all',\n",
       " 'age',\n",
       " 'groups',\n",
       " 'however',\n",
       " 'the',\n",
       " 'morbidity',\n",
       " 'mortality',\n",
       " 'is',\n",
       " 'several',\n",
       " 'times',\n",
       " 'higher',\n",
       " 'in',\n",
       " 'adults',\n",
       " 'particularly',\n",
       " 'in',\n",
       " 'those',\n",
       " 'above',\n",
       " 'the',\n",
       " 'age',\n",
       " 'of',\n",
       " '50',\n",
       " 'years',\n",
       " 'Children',\n",
       " 'have',\n",
       " 'either',\n",
       " 'asymptomatic',\n",
       " 'or',\n",
       " 'mild',\n",
       " 'infection',\n",
       " 'The',\n",
       " 'general',\n",
       " 'practice',\n",
       " 'is',\n",
       " 'to',\n",
       " 'first',\n",
       " 'evaluate',\n",
       " 'any',\n",
       " 'new',\n",
       " 'vaccine',\n",
       " 'in',\n",
       " 'older',\n",
       " 'population',\n",
       " 'and',\n",
       " 'then',\n",
       " 'age',\n",
       " 'reduction',\n",
       " 'is',\n",
       " 'done',\n",
       " 'to',\n",
       " 'assess',\n",
       " 'the',\n",
       " 'safety',\n",
       " 'and',\n",
       " 'effectiveness',\n",
       " 'in',\n",
       " 'paediatric',\n",
       " 'population',\n",
       " 'The',\n",
       " 'currently',\n",
       " 'available',\n",
       " 'vaccines',\n",
       " 'in',\n",
       " 'the',\n",
       " 'country',\n",
       " 'have',\n",
       " 'not',\n",
       " 'been',\n",
       " 'evaluated',\n",
       " 'in',\n",
       " 'children',\n",
       " 'so',\n",
       " 'far',\n",
       " 'There',\n",
       " 'are',\n",
       " 'some',\n",
       " 'clinical',\n",
       " 'trials',\n",
       " 'now',\n",
       " 'underway',\n",
       " 'to',\n",
       " 'test',\n",
       " 'the',\n",
       " 'effectiveness',\n",
       " 'and',\n",
       " 'safety',\n",
       " 'of',\n",
       " 'the',\n",
       " 'COVID',\n",
       " '19',\n",
       " 'vaccines',\n",
       " 'in',\n",
       " 'children',\n",
       " 'Phases',\n",
       " 'of',\n",
       " 'vaccine',\n",
       " 'development',\n",
       " 'trial',\n",
       " 'Purpose',\n",
       " 'Pre',\n",
       " 'clinical',\n",
       " 'Vaccine',\n",
       " 'development',\n",
       " 'in',\n",
       " 'laboratory',\n",
       " 'animals',\n",
       " 'Phase',\n",
       " 'I',\n",
       " 'Clinical',\n",
       " 'trial',\n",
       " 'small',\n",
       " 'number',\n",
       " 'of',\n",
       " 'participants',\n",
       " 'Assess',\n",
       " 'vaccine',\n",
       " 'safety',\n",
       " 'immune',\n",
       " 'response',\n",
       " 'and',\n",
       " 'determine',\n",
       " 'right',\n",
       " 'dosage',\n",
       " 'short',\n",
       " 'duration',\n",
       " 'Phase',\n",
       " 'II',\n",
       " 'Clinical',\n",
       " 'trial',\n",
       " 'few',\n",
       " 'hundred',\n",
       " 'participants',\n",
       " 'Assess',\n",
       " 'safety',\n",
       " 'and',\n",
       " 'the',\n",
       " 'ability',\n",
       " 'of',\n",
       " 'the',\n",
       " 'vaccine',\n",
       " 'to',\n",
       " 'generate',\n",
       " 'an',\n",
       " 'immune',\n",
       " 'response',\n",
       " 'short',\n",
       " 'duration',\n",
       " 'Phase',\n",
       " 'III',\n",
       " 'Clinical',\n",
       " 'trial',\n",
       " 'thousands',\n",
       " 'of',\n",
       " 'participants',\n",
       " 'Determine',\n",
       " 'vaccine',\n",
       " 'effectiveness',\n",
       " 'against',\n",
       " 'the',\n",
       " 'disease',\n",
       " 'and',\n",
       " 'safety',\n",
       " 'in',\n",
       " 'a',\n",
       " 'larger',\n",
       " 'group',\n",
       " 'of',\n",
       " 'people',\n",
       " 'duration',\n",
       " '1',\n",
       " '2',\n",
       " 'years',\n",
       " '3',\n",
       " 'B',\n",
       " 'VACCINE',\n",
       " 'ATTRIBUTES',\n",
       " '1',\n",
       " 'What',\n",
       " 'technology',\n",
       " 'has',\n",
       " 'been',\n",
       " 'used',\n",
       " 'in',\n",
       " 'development',\n",
       " 'of',\n",
       " 'the',\n",
       " 'currently',\n",
       " 'available',\n",
       " 'vaccines',\n",
       " 'in',\n",
       " 'India',\n",
       " 'Covishield',\n",
       " 'r',\n",
       " 'vaccine',\n",
       " 'manufactured',\n",
       " 'by',\n",
       " 'the',\n",
       " 'Serum',\n",
       " 'Institute',\n",
       " 'of',\n",
       " 'India',\n",
       " 'is',\n",
       " 'a',\n",
       " 'Viral',\n",
       " 'Vector',\n",
       " 'based',\n",
       " 'Technology',\n",
       " 'which',\n",
       " 'is',\n",
       " 'also',\n",
       " 'used',\n",
       " 'to',\n",
       " 'manufacture',\n",
       " 'Ebola',\n",
       " 'vaccine',\n",
       " 'Covaxin',\n",
       " 'r',\n",
       " 'vaccine',\n",
       " 'manufactured',\n",
       " 'by',\n",
       " 'the',\n",
       " 'Bharat',\n",
       " 'Biotech',\n",
       " 'is',\n",
       " 'a',\n",
       " 'whole',\n",
       " 'Virion',\n",
       " 'Inactivated',\n",
       " 'Corona',\n",
       " 'Virus',\n",
       " 'Vaccine',\n",
       " 'which',\n",
       " 'is',\n",
       " 'also',\n",
       " 'used',\n",
       " 'to',\n",
       " 'manufacture',\n",
       " 'vaccines',\n",
       " 'like',\n",
       " 'Influenza',\n",
       " 'Rabies',\n",
       " 'and',\n",
       " 'Hepatitis',\n",
       " 'A',\n",
       " 'Sputnik',\n",
       " 'V',\n",
       " 'is',\n",
       " 'developed',\n",
       " 'by',\n",
       " 'Gamaleya',\n",
       " 'Institute',\n",
       " 'in',\n",
       " 'Russia',\n",
       " 'and',\n",
       " 'is',\n",
       " 'working',\n",
       " 'closely',\n",
       " 'with',\n",
       " 'Dr',\n",
       " \"Reddy's\",\n",
       " 'Laboratories',\n",
       " 'for',\n",
       " 'Gam',\n",
       " 'COVID',\n",
       " 'Vac',\n",
       " 'Combined',\n",
       " 'vector',\n",
       " 'vaccine',\n",
       " '2',\n",
       " 'What',\n",
       " 'are',\n",
       " 'the',\n",
       " 'compositions',\n",
       " 'of',\n",
       " 'the',\n",
       " 'above',\n",
       " 'vaccines',\n",
       " 'Composition',\n",
       " 'of',\n",
       " 'Covishield',\n",
       " 'r',\n",
       " 'includes',\n",
       " 'inactivated',\n",
       " 'adenovirus',\n",
       " 'with',\n",
       " 'segments',\n",
       " 'of',\n",
       " 'Corona',\n",
       " 'Virus',\n",
       " 'Aluminium',\n",
       " 'Hydroxide',\n",
       " 'Gel',\n",
       " 'L',\n",
       " 'Histidine',\n",
       " 'L',\n",
       " 'Histidine',\n",
       " 'hydrochloride',\n",
       " 'monohydrate',\n",
       " 'Magnesium',\n",
       " 'chloride',\n",
       " 'hexahydrate',\n",
       " 'Polysorbate',\n",
       " '80',\n",
       " 'Ethanol',\n",
       " 'Sucrose',\n",
       " 'Sodium',\n",
       " 'chloride',\n",
       " 'and',\n",
       " 'Disodium',\n",
       " 'edetate',\n",
       " 'dihydrate',\n",
       " 'EDTA',\n",
       " 'Composition',\n",
       " 'of',\n",
       " 'Covaxin',\n",
       " 'r',\n",
       " 'includes',\n",
       " 'inactivated',\n",
       " 'Corona',\n",
       " 'Virus',\n",
       " 'Aluminium',\n",
       " 'Hydroxide',\n",
       " 'Gel',\n",
       " 'TLR',\n",
       " '7',\n",
       " '8',\n",
       " 'agonist',\n",
       " '2',\n",
       " 'Phenoxyethanol',\n",
       " 'and',\n",
       " 'Phosphate',\n",
       " 'Buffered',\n",
       " 'Saline',\n",
       " 'Composition',\n",
       " 'of',\n",
       " 'Sputnik',\n",
       " 'V',\n",
       " 'Component',\n",
       " 'I',\n",
       " 'Active',\n",
       " 'substance',\n",
       " 'replication',\n",
       " 'incompetent',\n",
       " 'recombinant',\n",
       " 'adenovirus',\n",
       " 'serotype',\n",
       " '26',\n",
       " 'particles',\n",
       " 'containing',\n",
       " 'the',\n",
       " 'SARS',\n",
       " 'CoV',\n",
       " '2',\n",
       " 'protein',\n",
       " 'S',\n",
       " 'gene',\n",
       " 'Component',\n",
       " 'II',\n",
       " 'Active',\n",
       " 'substance',\n",
       " 'replication',\n",
       " 'incompetent',\n",
       " 'recombinant',\n",
       " 'adenovirus',\n",
       " 'serotype',\n",
       " '5',\n",
       " 'particles',\n",
       " 'containing',\n",
       " 'SARS',\n",
       " 'CoV',\n",
       " '2',\n",
       " 'protein',\n",
       " 'S',\n",
       " 'gene',\n",
       " 'Excipients',\n",
       " 'Tris',\n",
       " 'hydroxymethyl',\n",
       " 'aminomethane',\n",
       " 'sodium',\n",
       " 'chloride',\n",
       " 'sucrose',\n",
       " 'magnesium',\n",
       " 'chloride',\n",
       " 'hexahydrate',\n",
       " 'EDTA',\n",
       " 'disodium',\n",
       " 'salt',\n",
       " 'dihydrate',\n",
       " 'polysorbate',\n",
       " '80',\n",
       " 'ethanol',\n",
       " '95',\n",
       " 'and',\n",
       " 'water',\n",
       " 'for',\n",
       " 'injection',\n",
       " '3',\n",
       " 'All',\n",
       " 'three',\n",
       " 'vaccines',\n",
       " 'require',\n",
       " 'cold',\n",
       " 'chain',\n",
       " 'temperature',\n",
       " 'How',\n",
       " 'is',\n",
       " 'the',\n",
       " 'cold',\n",
       " 'chain',\n",
       " 'been',\n",
       " 'maintained',\n",
       " 'during',\n",
       " 'storage',\n",
       " 'and',\n",
       " 'transportation',\n",
       " 'of',\n",
       " 'vaccine',\n",
       " 'The',\n",
       " 'two',\n",
       " 'vaccines',\n",
       " 'Covishield',\n",
       " 'Covaxin',\n",
       " 'need',\n",
       " 'to',\n",
       " 'be',\n",
       " 'stored',\n",
       " 'and',\n",
       " 'transported',\n",
       " 'at',\n",
       " '20',\n",
       " 'to',\n",
       " '8⁰',\n",
       " 'Celsius',\n",
       " 'The',\n",
       " 'cold',\n",
       " 'chain',\n",
       " 'for',\n",
       " 'the',\n",
       " 'vaccines',\n",
       " 'is',\n",
       " 'maintained',\n",
       " 'through',\n",
       " 'active',\n",
       " 'and',\n",
       " 'passive',\n",
       " 'cold',\n",
       " 'chain',\n",
       " 'equipment',\n",
       " 'available',\n",
       " 'at',\n",
       " 'approximately',\n",
       " '29',\n",
       " '000',\n",
       " 'cold',\n",
       " 'chain',\n",
       " 'points',\n",
       " 'across',\n",
       " 'India',\n",
       " 'Sputnik',\n",
       " 'V',\n",
       " 'requires',\n",
       " 'storage',\n",
       " 'temperature',\n",
       " 'of',\n",
       " '180C',\n",
       " 'minus',\n",
       " 'eighteen',\n",
       " 'degrees',\n",
       " 'centigrade',\n",
       " 'or',\n",
       " 'below',\n",
       " 'The',\n",
       " 'deep',\n",
       " 'freezers',\n",
       " 'are',\n",
       " 'available',\n",
       " 'under',\n",
       " 'Universal',\n",
       " 'Immunization',\n",
       " 'Programme',\n",
       " 'across',\n",
       " 'the',\n",
       " 'country',\n",
       " 'for',\n",
       " 'storage',\n",
       " 'of',\n",
       " 'this',\n",
       " 'vaccine',\n",
       " '4',\n",
       " 'Is',\n",
       " 'COVISHIELD',\n",
       " 'r',\n",
       " 'same',\n",
       " 'as',\n",
       " 'the',\n",
       " 'vaccine',\n",
       " 'been',\n",
       " 'given',\n",
       " 'in',\n",
       " 'UK',\n",
       " 'by',\n",
       " 'Astra',\n",
       " 'Zeneca',\n",
       " 'Yes',\n",
       " 'Covishield',\n",
       " 'r',\n",
       " 'vaccine',\n",
       " 'manufactured',\n",
       " 'by',\n",
       " 'the',\n",
       " 'Serum',\n",
       " 'Institute',\n",
       " 'of',\n",
       " 'India',\n",
       " 'is',\n",
       " 'based',\n",
       " 'on',\n",
       " 'the',\n",
       " 'same',\n",
       " 'patent',\n",
       " 'technology',\n",
       " 'as',\n",
       " 'the',\n",
       " 'AstraZeneca',\n",
       " 'vaccine',\n",
       " '4',\n",
       " '5',\n",
       " 'What',\n",
       " 'is',\n",
       " 'the',\n",
       " 'dose',\n",
       " 'schedule',\n",
       " 'of',\n",
       " 'the',\n",
       " 'vaccines',\n",
       " 'under',\n",
       " 'the',\n",
       " 'national',\n",
       " 'vaccination',\n",
       " 'program',\n",
       " 'As',\n",
       " 'per',\n",
       " 'the',\n",
       " 'permission',\n",
       " 'granted',\n",
       " 'by',\n",
       " 'the',\n",
       " 'Drugs',\n",
       " 'Controller',\n",
       " 'General',\n",
       " 'India',\n",
       " 'the',\n",
       " 'dose',\n",
       " 'schedule',\n",
       " 'is',\n",
       " 'as',\n",
       " 'follows',\n",
       " 'o',\n",
       " 'Covishield',\n",
       " 'r',\n",
       " 'two',\n",
       " 'doses',\n",
       " 'an',\n",
       " 'interval',\n",
       " 'of',\n",
       " '12',\n",
       " '16',\n",
       " 'weeks',\n",
       " 'o',\n",
       " 'Covaxin',\n",
       " 'r',\n",
       " 'two',\n",
       " 'doses',\n",
       " 'at',\n",
       " 'an',\n",
       " 'interval',\n",
       " 'of',\n",
       " '4',\n",
       " '6',\n",
       " 'weeks',\n",
       " '6',\n",
       " 'Do',\n",
       " 'I',\n",
       " 'have',\n",
       " 'a',\n",
       " 'choice',\n",
       " 'of',\n",
       " 'the',\n",
       " 'vaccine',\n",
       " 'that',\n",
       " 'I',\n",
       " 'will',\n",
       " 'receive',\n",
       " 'Yes',\n",
       " 'Co',\n",
       " 'WIN',\n",
       " 'portal',\n",
       " 'displays',\n",
       " 'the',\n",
       " 'availability',\n",
       " 'of',\n",
       " 'the',\n",
       " 'different',\n",
       " 'vaccines',\n",
       " 'across',\n",
       " 'the',\n",
       " 'COVID',\n",
       " 'Vaccination',\n",
       " 'Centres',\n",
       " 'both',\n",
       " 'government',\n",
       " 'and',\n",
       " 'private',\n",
       " 'The',\n",
       " 'beneficiary',\n",
       " 'can',\n",
       " 'choose',\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing tokenization of one of the texts\n",
    "pregnantWomenToken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4aa82b8",
   "metadata": {},
   "source": [
    "## Part 1: Basic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "021c3dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a: Length of each text, in number of words, number of sentences, and number of paragraphs or stanzas, if applicable.\n",
    "\n",
    "#function calculates the length of each text in number of words, number of sentences, and number of paragraphs\n",
    "#function requires tokenized and nontokenized versions of text\n",
    "def textStats(tokenizedText, text):\n",
    "    wordCount = len(tokenizedText) #counting number of tokens as words since punctuation has been removed\n",
    "    print('number of words is: ', wordCount) \n",
    "    sentCount = 0 \n",
    "    punctToken = nltk.word_tokenize(text) #this tokenizer includes punctuation\n",
    "    sentStop = ['.', '!', '?'] #indicators of sentence end\n",
    "    for char in punctToken: \n",
    "        if char in sentStop: #if token is one of the sentence stoppers, counter increases, thus counting sentences\n",
    "            sentCount += 1\n",
    "            #print(punctToken)\n",
    "    print('number of sentences is: ', sentCount)\n",
    "    \n",
    "    for char in text:\n",
    "        paraCount = 0\n",
    "        if '\\n' in char: #since \\n indicates new line, counter increases with each \\n to count a new paragraph\n",
    "            paraCount += 1\n",
    "    print('number of paragraphs is: ', paraCount)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e647ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words is:  6403\n",
      "number of sentences is:  388\n",
      "number of paragraphs is:  1\n"
     ]
    }
   ],
   "source": [
    "textStats(pregnantWomenToken, pregnantWomen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f305949e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words is:  1178\n",
      "number of sentences is:  46\n",
      "number of paragraphs is:  1\n"
     ]
    }
   ],
   "source": [
    "textStats(nationalGuidelinesToken, nationalGuidelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "400abe81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words is:  2123\n",
      "number of sentences is:  85\n",
      "number of paragraphs is:  1\n"
     ]
    }
   ],
   "source": [
    "textStats(elderlyToken, elderly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d30f9936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words is:  2121\n",
      "number of sentences is:  85\n",
      "number of paragraphs is:  1\n"
     ]
    }
   ],
   "source": [
    "textStats(IDToken, ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3adde0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words is:  11825\n",
      "number of sentences is:  604\n",
      "number of paragraphs is:  1\n"
     ]
    }
   ],
   "source": [
    "textStats(ayushToken, ayush)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5838893a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a1ce622",
   "metadata": {},
   "outputs": [],
   "source": [
    "#c Part-of-speech distribution for each section\n",
    "\n",
    "#this function POS tags tokenized text and then returns a list of all the tags\n",
    "def POStag(tokenizedText):\n",
    "    textPOS = nltk.pos_tag(tokenizedText)\n",
    "    tags = []\n",
    "    for (w1, t1) in textPOS: #tuple form that the POS tags are arranged in\n",
    "        tags.append(t1) #thus we take only the POS tag and not the word\n",
    "    #print(tags)\n",
    "    return(FreqDist(tags))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da87c485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'NN': 1169, 'IN': 848, 'NNP': 711, 'DT': 547, 'JJ': 478, 'NNS': 433, 'CD': 312, 'VB': 238, 'VBN': 226, 'CC': 220, ...})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POStag(pregnantWomenToken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b157ce54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'NN': 184, 'IN': 163, 'NNP': 159, 'DT': 89, 'JJ': 85, 'NNS': 82, 'VBN': 54, 'VB': 54, 'TO': 49, 'CC': 46, ...})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POStag(nationalGuidelinesToken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1dc76df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'NN': 374, 'NNP': 370, 'IN': 292, 'JJ': 151, 'DT': 141, 'NNS': 136, 'VB': 111, 'VBN': 85, 'CD': 80, 'CC': 78, ...})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POStag(elderlyToken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3c3f071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'NN': 374, 'NNP': 368, 'IN': 292, 'JJ': 151, 'DT': 141, 'NNS': 136, 'VB': 111, 'VBN': 85, 'CD': 80, 'CC': 78, ...})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POStag(IDToken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a4a638e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'NN': 2101, 'NNP': 1610, 'IN': 1595, 'DT': 918, 'JJ': 865, 'NNS': 787, 'VB': 514, 'CD': 504, 'VBN': 450, 'CC': 422, ...})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POStag(ayushToken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03c03d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#d Ratio of male pronouns to female pronouns\n",
    "\n",
    "#this function takes in tokenized text and returns the male:female pronouns ratio in the text\n",
    "def pronounRatio(tokenizedText):\n",
    "    male = ['he', 'him', 'his']\n",
    "    maleCount = 0\n",
    "    for word in tokenizedText: \n",
    "        if word in male: #for each instance of male pronouns increase counter\n",
    "            maleCount += 1\n",
    "    print('male pronoun count is: ', maleCount)\n",
    "    \n",
    "    female = ['she', 'her', 'hers']\n",
    "    femaleCount = 0\n",
    "    for word in tokenizedText:\n",
    "        if word in female: #for each instance of female pronouns increase counter\n",
    "            femaleCount += 1\n",
    "    print('female pronoun count is: ', femaleCount)\n",
    "    \n",
    "    if femaleCount == 0:\n",
    "        print('no ratio possible') #if denominator is 0, no divison possible\n",
    "    else: \n",
    "        ratio = maleCount/femaleCount #if nonzero numerator, divide to find ratio\n",
    "        print('ratio of male pronouns to female pronouns is: ', ratio)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4f880c",
   "metadata": {},
   "source": [
    "100.00–90.00\t5th grade\tVery easy to read. Easily understood by an average 11-year-old student.\n",
    "90.0–80.0\t6th grade\tEasy to read. Conversational English for consumers.\n",
    "80.0–70.0\t7th grade\tFairly easy to read.\n",
    "70.0–60.0\t8th & 9th grade\tPlain English. Easily understood by 13- to 15-year-old students.\n",
    "60.0–50.0\t10th to 12th grade\tFairly difficult to read.\n",
    "50.0–30.0\tCollege\tDifficult to read.\n",
    "30.0–10.0\tCollege graduate\tVery difficult to read. Best understood by university graduates.\n",
    "10.0–0.0\tProfessional\tExtremely difficult to read. Best understood by university graduates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9005be8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male pronoun count is:  2\n",
      "female pronoun count is:  6\n",
      "ratio of male pronouns to female pronouns is:  0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "pronounRatio(pregnantWomenToken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb551fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male pronoun count is:  0\n",
      "female pronoun count is:  0\n",
      "no ratio possible\n"
     ]
    }
   ],
   "source": [
    "pronounRatio(nationalGuidelinesToken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03c48179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male pronoun count is:  0\n",
      "female pronoun count is:  0\n",
      "no ratio possible\n"
     ]
    }
   ],
   "source": [
    "pronounRatio(elderlyToken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "860a1f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male pronoun count is:  0\n",
      "female pronoun count is:  0\n",
      "no ratio possible\n"
     ]
    }
   ],
   "source": [
    "pronounRatio(IDToken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "09947d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male pronoun count is:  2\n",
      "female pronoun count is:  6\n",
      "ratio of male pronouns to female pronouns is:  0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "pronounRatio(ayushToken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "870449cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#e: Readability score for each\n",
    "\n",
    "#this function takes in nontokenized text and returns flesch kincaid readability score\n",
    "def readability(text):\n",
    "    read = Readability(text) #through imported readability module\n",
    "    fk = read.flesch_kincaid()\n",
    "    print(fk.score)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4af1c950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.371484843222106\n"
     ]
    }
   ],
   "source": [
    "readability(pregnantWomen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8b9b7e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.087509479807093\n"
     ]
    }
   ],
   "source": [
    "readability(nationalGuidelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0132104b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.600812211269346\n"
     ]
    }
   ],
   "source": [
    "readability(elderly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "86f2dab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.573347734611449\n"
     ]
    }
   ],
   "source": [
    "readability(ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8c184a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.062227052867758\n"
     ]
    }
   ],
   "source": [
    "readability(ayush)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665b61bb",
   "metadata": {},
   "source": [
    "### Write a paragraph or two about what you notice happening in your results, and what that might tell you about your corpus.\n",
    "\n",
    "The chosen tests revealed a lot about the project of the Indian government's vaccination effort and their methods of achieving their goals. Firstly, the basic stats about each text's length and word and paragraph count revealed that all the memos have an average sentence of length of 15-25 words. That is not extremely complicated (like theory heavy texts might be), but they are not made up of short, clear sentences either. Their readability scores are between 11 and 16. This would put them in the grade level \"college graduate\", according to the Flesch Kincaid system. This means they are generally very difficult to read and best understood by university graduates. When only 14% of Indians can speak English, and an even smallerr percent can read basic English, these memos are highly inaccessible to the general population. \n",
    "\n",
    "The clunky language comes from the lack of pronouns and verbs. As one can see, the five texts together only had 16 pronouns! This is because the memos are written in passive language, never addresseing any particular person. Thus, it makes sense that nouns--all different kinds of nouns--are consistently the most frequent part of speech through the texts in the corpus. I was especially surpised when there werer only 6 instances of female pronouns in the memo about pregnantWomen. When I went to read the passage again, I found that this was because it was written in a passive and detached voice. The few times female pronouns come up is when the text mentions 'her choice' to get the vaccine. Similarly, in Ayush, which discusses home remedies and immunity, the pronouns refer to passages that talk about 'his/her immmunity'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f520e1a",
   "metadata": {},
   "source": [
    "## Part 2: Advanced Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e4770b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7c WordNet-based lexical categorizer. Use WordNet to categorize the words in your texts to a given depth. \n",
    "#Create some sort of visualization with your results.\n",
    "\n",
    "#this function takes in tokenized text and returns a dictionary of the hypernyms of the tokens\n",
    "def categorizerHypernyms(tokens, depth=6):\n",
    "    hypernymDict = {}\n",
    "    Freqs = nltk.FreqDist(tokens)\n",
    "    tokensFreq = nltk.FreqDist(tokens)\n",
    "    FreqSorted = sorted(tokensFreq, key=tokensFreq.get, reverse=True)\n",
    "    Semantic = FreqSorted[500:]\n",
    "    SemanticFreq = {word: tokensFreq[word] for word in Semantic}\n",
    "    for word, freq in SemanticFreq.items():\n",
    "        synsets = wn.synsets(word)\n",
    "        if len(synsets) > 0:\n",
    "            synset = synsets[0]\n",
    "            while synset.max_depth() < depth:\n",
    "                hypernyms = synset.hypernyms()\n",
    "                if len(hypernyms) > 0:\n",
    "                    hypernym = hypernyms[0]\n",
    "                    synset = hypernym\n",
    "                else:\n",
    "                    break\n",
    "                hypernymDict[word] = hypernym\n",
    "                if hypernym is not None:\n",
    "                    hypernymDict[word] = hypernym\n",
    "    return hypernymDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1d78b293",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorizePreg = categorizerHypernyms(pregnantWomenToken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d77a30f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorizeID = categorizerHypernyms(IDToken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a5ece39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorizeNatnl = categorizerHypernyms(nationalGuidelinesToken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "69e247df",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorizeEld = categorizerHypernyms(elderlyToken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "909485b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorizeAyush = categorizerHypernyms(ayushToken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f62d4139",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function takes the word-synset categories, counts and displays them through a word clouf\n",
    "def visualisation(synset_categories): \n",
    "    catCount = {} #count of categories\n",
    "    c\n",
    "    for x in synset_categories:\n",
    "        if synset_categories[x] not in catList: #everytime we see a new category, we add it to the dict\n",
    "            catCount[str(synset_categories[x])] = 1 \n",
    "        else: #everytime we re-encounter a category we increase its counter by 1 \n",
    "            catCount[str(synset_categories[x])] = catCount[str(synset_categories[x])] + 1\n",
    "\n",
    "    #now we have a list of the cateogires and their frequencies, and we convert those into a word cloud using \n",
    "    #the worldcloud package so that we can visualize their freqeuncies\n",
    "    wordcloud = WordCloud(background_color=\"white\", width = 1000, height = 500).generate_from_frequencies(catCount)\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plt.imshow(wordcloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c8628b89",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'c' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-4b2f7b22b114>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvisualisation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategorizePreg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-45-aaf73d87d287>\u001b[0m in \u001b[0;36mvisualisation\u001b[0;34m(synset_categories)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvisualisation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msynset_categories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcatCount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;31m#count of categories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msynset_categories\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msynset_categories\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcatList\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#everytime we see a new category, we add it to the dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'c' is not defined"
     ]
    }
   ],
   "source": [
    "visualisation(categorizePreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ed102c",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualisation(categorizeEld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a178c5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualisation(categorizeID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a96471",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualisation(categorizeAyush)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c30f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorizerHypernyms(pregnantWomenToken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43f99c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorizerHypernyms(IDToken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8bd3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorizerHypernyms(elderlyToken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3569aa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorizerHypernyms(ayushToken)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c754f2",
   "metadata": {},
   "source": [
    "### 7c: Wordnet Lexical Catogorizer Analysis: write 2-3 paragraphs where you interpret what you see happening.\n",
    "This analysis examined the hypernyms of the words in the IndiaVax corpus. Hypernyms are words with broad meanings under which more words fall. Wordnet groups these hypernyms in synsets, which are sets of words correlated by nouns, verbs, adjectives, adverbs, synonyms, antonyms, and more. This tree like stacked understanding of the words in the text and their associations can help make better sense of the meaning and project of the text, which might not have been apparent at first glance. \n",
    "\n",
    "In order to better visualize the synsets of the texts in the IndiaVax corpus, I chose to use a word cloud. The world cloud displays words related to their frequency -- the more frequent the word, the bigger it will appear on the cloud. Broadly, the most common synset across the texts is \"entity\". Since entity is a very broad category since it means something with a distinct and independent existence, many words would fit under that category, regardless of topic. Thus, it is not that helpful in discerning the project of each text. It is ironic that one of the largest words in the word cloud of ID is 'join', since the document addresses the difficulties of those without documentation -- those who are not safely joined to the country. \n",
    "\n",
    "Interestingly, ayush, which is the memo about immunity and natural remedies, has many words in the synsets 'act', 'think', and 'change'. The 'change' is especially illuminating, as it reveals that many of the words in ayush are pushing for action and modification of routine. Thus, this synset helps us answer the question from earlier about what is the project of the state in making a memo about home remedies in the context of covid. Here, one can see that the government is not merely desribing the existence of home remedies, but really encouraging and recommending Yoga and Ayurvedic cures. When seen in the context of a rightwing government that has previously co-opted Yoga as a took of its violent Hindu nationalism, it is clear that these memos in fact represent a political project carried out through the rhetoric of public health."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a86e77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7g: A comparative sentiment analysis of each of your texts.\n",
    "\n",
    "#this function takes in text and returns a sentiment analysis polarity score of the text\n",
    "def sentimentAnalyzer(text):\n",
    "    sentAn = SentimentIntensityAnalyzer()\n",
    "    score = sentAn.polarity_scores(text)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d9fdb41b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "polarity_scores() missing 1 required positional argument: 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-98826ee79e42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msentAn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolarity_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"covid\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#testing to see how some common words in the corpus are scored\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: polarity_scores() missing 1 required positional argument: 'text'"
     ]
    }
   ],
   "source": [
    "sentAn.polarity_scores(\"covid\") #testing to see how some common words in the corpus are scored "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "244027a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "polarity_scores() missing 1 required positional argument: 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-0195b7686c6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msentAn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolarity_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"vaccine\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#testing to see how some common words in the corpus are scored\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: polarity_scores() missing 1 required positional argument: 'text'"
     ]
    }
   ],
   "source": [
    "sentAn.polarity_scores(\"vaccine\") #testing to see how some common words in the corpus are scored "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33856185",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentAn.polarity_scores(\"disease\") #testing to see how some common words in the corpus are scored "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d57367",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentAn.polarity_scores(\"sick\") #testing to see how some common words in the corpus are scored "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b93c22",
   "metadata": {},
   "outputs": [],
   "source": [
    " sentimentAnalyzer(pregnantWomen) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2a3152",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimentAnalyzer(nationalGuidelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626f96d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimentAnalyzer(elderly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d28a106",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimentAnalyzer(ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac0f8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimentAnalyzer(ayush)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c79726",
   "metadata": {},
   "source": [
    "### 7g: Comparitive Sentiment Analysis: write 2-3 paragraphs where you interpret what you see happening.\n",
    "\n",
    "I was especially curious to do a sentiment analysis of this corpus because I was not sure at all what I would find. On one hand, these texts are government documents written in highly dry and impassionate prose. This hinted that the socres might be overall neutral. However, the topics of all the memos are about Covid, disease, illness, and disability. Thus, the content would suggest that the overall sentiment would be negative.\n",
    "\n",
    "Sentiment analysis scores can be understood on a scale between -1 and 1. A -1 would mean the text is entirely negative. A one is entirely positive. Anything below a score of -0.05 is tagged as negative and anything above 0.05 is tagged as positive. Anything in between inclusively is neutral. Extremely surpisingly, the compound scores of all the texts were really close to one. They were all above .99. This was surprising, so I began to test the sentiment analysis score of individual words would occur widely across the texts like \"covid\", \"vaccine\", and \"disease\". I saw that the analyzer actually labeled these words as neutral, though in my understanding I would classify \"covid\" and \"disease\" as negative. Although \"disease\" was neutral, it classified \"sick\" as negative. This would mean that since the texts are written in passive tense, even though they address topics of illness, death, and injury, those are probably classified as neutral, and thus do not balance out the general positive words, thus resulting in a really high positive score.\n",
    "\n",
    "Interestingly, ayush got a perfect score of 1.0. I think this is because the analyzer probably struggled to evaluate a great many of the words in the text as they had to do with Indian homeopathy and Ayurvedic practice. Words like \"Ritucharya\" (seasonal regimes to maintain healthy life), \"Chyavanprash\" (an extremely popular but horrible tasting vitamin supplement, ubiquitously hated by kids), etc were deemed as neutral by the analyzer despite them posessing sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6656e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994f4b62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9277eb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fed1131",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc5b16b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
